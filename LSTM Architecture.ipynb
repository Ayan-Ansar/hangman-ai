{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "14f61090-6919-44ec-988d-8dcb05393203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pickle \n",
    "import random \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(220);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29bd3290-59ab-4788-a2c0-aa1ff7ba4598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda'\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'{device = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7464818-7563-4ee2-bf50-93c309416ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_250000_train.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b593ff34-335f-42bc-a14f-84a73562a1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thyreohyal',\n",
       " 'verdancy',\n",
       " 'nonbolshevism',\n",
       " 'norml',\n",
       " 'consecrating',\n",
       " 'ginhound',\n",
       " 'yaffed',\n",
       " 'beats',\n",
       " 'squarechinned',\n",
       " 'skiagraphic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(text)\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d36d949-18d9-4153-a8c3-6db55278318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen = 29\n"
     ]
    }
   ],
   "source": [
    "maxlen = max(len(words) for words in text)\n",
    "print(f'{maxlen = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186bb372-21f0-4106-96a3-7f2b91a13490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 27\n"
     ]
    }
   ],
   "source": [
    "charset = sorted(list(set(''.join(text))))\n",
    "stoi = {c:idx+1 for idx,c in enumerate(charset)}\n",
    "itos = {idx+1:c for idx,c in enumerate(charset)}\n",
    "stoi['.'] = 0\n",
    "itos[0] = '.'\n",
    "encode = lambda x: [stoi[i] for i in x] \n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "vocab_size = len(stoi)\n",
    "print(f'{vocab_size = }') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6f9bc9-8b64-4813-bec0-95e5c778ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = 'subgape'\n"
     ]
    }
   ],
   "source": [
    "word = random.sample(text, 1)[0]\n",
    "print(f'{word = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4d2a8d-8fa8-46bd-93d3-0c0aadfe54ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = [19, 21, 2, 7, 1, 16, 5]\n"
     ]
    }
   ],
   "source": [
    "encoded = encode(word)\n",
    "print(f'{encoded = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "112c0b88-7e57-4672-a83f-08fbb0786e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = 'subgape'\n"
     ]
    }
   ],
   "source": [
    "decoded = decode(encoded)\n",
    "print(f'{decoded = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5d0f128f-4ac0-4d7f-832d-f218eb4b01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    x = []\n",
    "    y = []\n",
    "    for word in words:\n",
    "        encoded = np.array(encode(word))\n",
    "        input = np.zeros_like(encoded)\n",
    "        x.append(input) \n",
    "        sorted_letter_count = Counter(word).most_common()\n",
    "        g = [0]*26\n",
    "        prev = x[-1].copy()\n",
    "        while not np.all(prev != 0):\n",
    "            prev = x[-1].copy()\n",
    "            for letter, _ in sorted_letter_count:\n",
    "                idx = ord(letter) - ord('a')\n",
    "                if g[idx] != 1:\n",
    "                    g[idx] = 1\n",
    "                    g_in = stoi[letter]\n",
    "                    break\n",
    "            y.append(g_in)\n",
    "            idxs = np.where(encoded == g_in)[0]\n",
    "            prev[idxs] = g_in \n",
    "            if np.any(prev == 0):\n",
    "                x.append(prev)\n",
    "            \n",
    "    # adding paddding to every input \n",
    "    return x , y \n",
    "\n",
    "random.shuffle(text)\n",
    "n1 = int(0.9*len(text))\n",
    "n2 = int(0.95*len(text))\n",
    "\n",
    "Xtr, Ytr = build_dataset(text[:n1])\n",
    "Xval, Yval = build_dataset(text[n1:n2])\n",
    "Xts, Yts  = build_dataset(text[n2:])\n",
    "\n",
    "# Xtr, Ytr = load_split('train')\n",
    "# Xval, Yval = load_split('val')\n",
    "# Xts, Yts = load_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a477614f-ee5b-485c-8e30-16d3c8e9fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : 1513133 1513133\n",
      "Val Shape : 83936 83936\n",
      "Test Shape : 84140 84140\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Shape : {len(Xtr)} {len(Ytr)}')\n",
    "print(f'Val Shape : {len(Xval)} {len(Yval)}')\n",
    "print(f'Test Shape : {len(Xts)} {len(Yts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "353f9b44-42ef-41fd-a1bc-78c7952513a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparemters \n",
    "learning_rate = 1e-3\n",
    "n_embd = 32\n",
    "hidden_size = 128\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8540f048-0197-46c7-a60c-02d797d816fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data  = {'train': (Xtr, Ytr),\n",
    "            'val' : (Xval, Yval)}[split]\n",
    "    ix = np.random.randint(0, len(Xtr), (32,))\n",
    "    xb, yb = Xtr[ix], Ytr[ix]\n",
    "    return xb, yb\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def split_loss():\n",
    "    model.eval()\n",
    "    out = {}\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(200)\n",
    "        for k in range(200):\n",
    "            xb, yb = get_batch(split)\n",
    "            logits, loss = model(xb,yb)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "841eb1ca-711b-426e-b31f-b06554240aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_embd, hidden_size, vocab_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size \n",
    "        self.tok_embeddings = nn.Embedding(vocab_size, n_embd)\n",
    "        self.i2h = nn.Linear(n_embd + hidden_size, hidden_size)\n",
    "        self.i2m = nn.Linear(n_embd + hidden_size, hidden_size)\n",
    "        self.u_gate = nn.Linear(n_embd + hidden_size, 1)\n",
    "        self.f_gate = nn.Linear(n_embd + hidden_size, 1)\n",
    "        self.o_gate = nn.Linear(n_embd + hidden_size, 1)\n",
    "        self.i2o = nn.Linear(n_embd + hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x_t, hidden_state, memory_state):\n",
    "        x = self.tok_embeddings(x_t).view(1,-1)\n",
    "        x = torch.cat((hidden_state, x), dim=-1)\n",
    "        memory_update = torch.tanh(self.i2m(x))\n",
    "        update = torch.sigmoid(self.u_gate(x))\n",
    "        forget = torch.sigmoid(self.f_gate(x))\n",
    "        output = torch.sigmoid(self.o_gate(x))\n",
    "        memory_state = update * memory_update + forget * memory_state\n",
    "        hidden_state = output * torch.tanh(memory_state)\n",
    "        y_pred = self.i2o(x)\n",
    "        return y_pred, hidden_state, memory_state\n",
    "\n",
    "    def init_hidden_memory(self):\n",
    "        return torch.zeros(1, self.hidden_size), torch.zeros(1, self.hidden_size)\n",
    "\n",
    "    def guessletter(self, context, h, memory_stat, guessed_letters):\n",
    "        for t in range(context.size()[0]):\n",
    "            y_pred, h, m = lstm(context[t], h, m)\n",
    "        \n",
    "        probs = F.softmax(y_pred, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        while guessed_letters[ix-2] == 1:\n",
    "            ix = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        return ix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8e62bd7c-7c49-4246-ad24-b175a61aab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(n_embd, hidden_size, vocab_size)\n",
    "# model = lstm\"\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(), lr=1e-3)\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f4e90679-ed6f-4992-8b49-d9372e93a0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46910"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in lstm.parameters(recurse=True))\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "356bd1f4-7376-48b5-9186-536f50aaf5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in range(10):\n",
    "    h, m = lstm.init_hidden_memory()\n",
    "    loss = 0\n",
    "    for x, y in zip(Xtr[:10000], Ytr):\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        seq_len = len(x)\n",
    "        for t in range(seq_len):\n",
    "            y_pred, h, m = lstm(x[t], h, m)\n",
    "            \n",
    "        probs = F.softmax(y_pred, dim=1)\n",
    "        loss += -probs[:, y].log10()\n",
    "    print(f'{i} / {10} : {loss.item()}')\n",
    "    lossi.append(loss.item())\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b1746-7cd8-4d33-8c15-efc1f88ab60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "fb5c5fb8-4f6e-4e46-8160-a5fc340c852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(word):\n",
    "    context = [0] * len(word)\n",
    "    encoded = encode(word)\n",
    "    chances = 12\n",
    "    guessed_letters = [0]*26 \n",
    "    context = torch.tensor(context).to(device)\n",
    "    while chances > 0:\n",
    "        ix = model.guessletter(context, h, m, guessed_letters)\n",
    "        guessed_letters[ix-2] = 1 \n",
    "        idx = np.where(np.array(encoded) == ix)[0]\n",
    "        if idx.size != 0:\n",
    "            context[idx] = ix\n",
    "        else:\n",
    "            chances -= 1\n",
    "        w = np.array(context).cpu()\n",
    "        print(f'Guessed --- {itos[ix]} for Context {decode(w)}') \n",
    "        if decode(w) == word:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "89b35705-9e30-4c2b-b966-f74760429f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessed --- o for Context .oo.....\n",
      "Guessed --- r for Context .oo.....\n",
      "Guessed --- r for Context .oo.....\n",
      "Guessed --- s for Context .oo.....\n",
      "Guessed --- r for Context .oo.....\n",
      "Guessed --- i for Context .oo.....\n",
      "Guessed --- o for Context .oo.....\n",
      "Guessed --- r for Context .oo.....\n",
      "Guessed --- i for Context .oo.....\n",
      "Guessed --- m for Context .oo.....\n",
      "Guessed --- r for Context .oo.....\n",
      "Guessed --- t for Context .oot....\n",
      "Guessed --- o for Context .oot....\n",
      "Guessed --- e for Context .oot....\n",
      "Guessed --- p for Context .oot....\n",
      "Guessed --- m for Context .oot....\n"
     ]
    }
   ],
   "source": [
    "play('football')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7155cd51-c2b2-4295-9b77-933a70b1e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "# Sample sequences with variable lengths\n",
    "sequences = [torch.tensor([1, 2, 3]), torch.tensor([4, 5]), torch.tensor([6, 7, 8, 9])]\n",
    "\n",
    "# Pad sequences\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "\n",
    "# Sort sequences by length\n",
    "sorted_lengths, sorted_indices = torch.sort(torch.tensor([len(seq) for seq in sequences]), descending=True)\n",
    "sorted_sequences = padded_sequences[sorted_indices]\n",
    "\n",
    "# Pack padded sequences\n",
    "packed_sequences = pack_padded_sequence(sorted_sequences, lengths=sorted_lengths, batch_first=True)\n",
    "\n",
    "# Now 'packed_sequences' can be used in a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb6357-bf7a-4da7-840d-32dfb47fd1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
