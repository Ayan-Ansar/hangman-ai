{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d066b6-47db-4200-ae7e-db3a84824b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(220);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45d4c34-9cc4-4a7a-8b2e-db2dc931e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_250000_train.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662571b5-421a-47a3-be9f-4839ebfa4365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 28\n"
     ]
    }
   ],
   "source": [
    "charset = sorted(list(set(''.join(text))))\n",
    "stoi = {c:idx+2 for idx,c in enumerate(charset)}\n",
    "itos = {idx+2:c for idx,c in enumerate(charset)}\n",
    "stoi['.'] = 1 \n",
    "itos[1] = '.'\n",
    "stoi[''] = 0\n",
    "itos[0] = ''\n",
    "encode = lambda x: [stoi[i] for i in x] \n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "vocab_size = len(stoi)\n",
    "print(f'{vocab_size = }') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753bf6bf-5cce-427c-bb20-ac14dcd720e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [3, 4, 5, 7, 8, 9, 12, 13, 14, 15, 17, 19, 20, 21, 26], 1: [2, 6, 10, 16, 22], 2: [11, 18, 25, 27, 23, 24]}\n"
     ]
    }
   ],
   "source": [
    "common_letters = ('b', 'c', 'd','f', 'g', 'h', 'k' ,'l', 'm' ,'n' ,'p', 'r', 's', 't', 'y')\n",
    "vowels = ('a','e','i','o','u')\n",
    "uncommon_letters = ('j', 'q', 'x', 'z','v', 'w')\n",
    "\n",
    "# indicators  \n",
    "indicators = {0 :[stoi[c] for c in common_letters],\n",
    "              1 : [stoi[v] for v in vowels],\n",
    "              2 : [stoi[u] for u in uncommon_letters]}\n",
    "\n",
    "print(indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae5d9c0-9a49-4028-90cc-5d6fd641fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_dataset(words):\n",
    "#     x_temp = []\n",
    "#     y = []\n",
    "#     for word in words:\n",
    "#         encoded = np.array(encode(word))\n",
    "#         input = np.ones_like(encoded)\n",
    "#         x_temp.append(input) \n",
    "#         sorted_letter_count = Counter(word).most_common()\n",
    "#         g = [0]*26\n",
    "#         prev = x_temp[-1].copy()\n",
    "#         while not np.all(prev != 1):\n",
    "#             prev = x_temp[-1].copy()\n",
    "#             for letter, _ in sorted_letter_count:\n",
    "#                 idx = ord(letter) - ord('a')\n",
    "#                 if g[idx] != 1:\n",
    "#                     g[idx] = 1\n",
    "#                     g_in = stoi[letter]\n",
    "#                     break\n",
    "#             y.append(g_in)\n",
    "#             idxs = np.where(encoded == g_in)[0]\n",
    "#             prev[idxs] = g_in \n",
    "#             if np.any(prev == 1):\n",
    "#                 x_temp.append(prev)\n",
    "            \n",
    "#     # adding paddding to every input \n",
    "#     x = []\n",
    "#     for ix in x_temp:\n",
    "#         extra = maxlen - len(ix)\n",
    "#         pad = np.array([0]*extra)\n",
    "#         x_in = np.concatenate((ix, pad))\n",
    "#         x.append(x_in)\n",
    "    \n",
    "#     x = torch.tensor(np.array(x), dtype=torch.long)\n",
    "#     y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "#     return x,y \n",
    "\n",
    "# def queries_data(words):\n",
    "#     x = []\n",
    "#     y = [] \n",
    "#     '''\n",
    "#         y can be info about the word \n",
    "#             1. length of the word\n",
    "#             2. vowel count\n",
    "#             3. consonant count\n",
    "            \n",
    "#     '''\n",
    "    \n",
    "\n",
    "# random.shuffle(text)\n",
    "# n1 = int(0.9*len(text))\n",
    "# n2 = int(0.95*len(text))\n",
    "\n",
    "# # Xtr, Ytr = build_dataset(text[:n1])\n",
    "# # Xval, Yval = build_dataset(text[n1:n2])\n",
    "# # Xts, Yts  = build_dataset(text[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f192d694-a338-4468-97a0-eb7ae235c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(split):\n",
    "    try:\n",
    "        with open(f'data\\X_{split}.pkl', 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "    try:\n",
    "        with open(f'data\\Y_{split}.pkl', 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    return X, Y \n",
    "\n",
    "Xtr, Ytr = load_split('train')\n",
    "Xval, Yval = load_split('val')\n",
    "Xts, Yts = load_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ebfc2d-1988-4c34-ad6a-0958a30b09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : torch.Size([1513485, 29]) torch.Size([1513485])\n",
      "Val Shape : torch.Size([84078, 29]) torch.Size([84078])\n",
      "Test Shape : torch.Size([83646, 29]) torch.Size([83646])\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Shape : {Xtr.shape} {Ytr.shape}')\n",
    "print(f'Val Shape : {Xval.shape} {Yval.shape}')\n",
    "print(f'Test Shape : {Xts.shape} {Yts.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fe05ef4-4bc5-4841-8965-fbad90650249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    X, Y   = {'train': (Xtr, Ytr),\n",
    "            'val' : (Xval, Yval)}[split]\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    xb, yb = X[ix], Y[ix]\n",
    "    return xb, yb\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def split_loss():\n",
    "    # model.eval()\n",
    "    out = {}\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(200)\n",
    "        for k in range(200):\n",
    "            xb, yb = get_batch(split)\n",
    "            logits, loss = model(xb,yb)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    # model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd26677-9895-491f-8199-d1019ea058c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9eb57bf-d9c5-4b24-88ce-d1d0ffb621ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_X2_rep = np.tile(np.arange(0, 3).reshape([1, 3]), [32, 1]).flatten('F').reshape([32 * 3, 1])\n",
    "print(batch_X2_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7472ffc-41f7-4e35-a290-d75f2c5baedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_rep = np.tile(xb, [3,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b817189-de27-452a-afa9-f076da7a96b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 29)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db48cca7-30b6-42f0-a98c-be5ca5916ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = yb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c59fbd7-6163-40c4-92dc-82727cc112da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21,  2,  7,  6, 13, 10, 20,  2, 14,  4,  8, 17, 15, 10, 21,  4,  8,\n",
       "       16, 24, 17, 17,  6,  6, 19,  3, 12,  5,  6, 19,  7, 10, 19],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13ebddda-c4ec-499f-8834-2c3d5ec823c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = np.tile(\n",
    "        np.array(list(map(lambda x: [k for k, v in indicators.items() if x in v], y_np))) ,\n",
    "        [3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c9fb902-b649-4840-b01d-c61598475610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1e1a4-3ace-40a2-9975-ed0382d3b2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
